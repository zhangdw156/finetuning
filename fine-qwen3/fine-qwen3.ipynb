{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cea520a-9dbe-4157-a8d7-bae0b27d0ac8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 下载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd0377ba-8e35-4df0-8acd-8a99c6410a9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fine/uv/transformers/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has been split successfully.\n",
      "Train Set Size：2166\n",
      "Val Set Size：241\n"
     ]
    }
   ],
   "source": [
    "from modelscope.msdatasets import MsDataset\n",
    "import json\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "ds = MsDataset.load('krisfu/delicate_medical_r1_data', subset_name='default', split='train')\n",
    "data_list = list(ds)\n",
    "random.shuffle(data_list)\n",
    "\n",
    "split_idx = int(len(data_list) * 0.9)\n",
    "\n",
    "train_data = data_list[:split_idx]\n",
    "val_data = data_list[split_idx:]\n",
    "\n",
    "with open('../dataset/delicate_medical_r1/train.jsonl', 'w', encoding='utf-8') as f:\n",
    "    for item in train_data:\n",
    "        json.dump(item, f, ensure_ascii=False)\n",
    "        f.write('\\n')\n",
    "\n",
    "with open('../dataset/delicate_medical_r1/val.jsonl', 'w', encoding='utf-8') as f:\n",
    "    for item in val_data:\n",
    "        json.dump(item, f, ensure_ascii=False)\n",
    "        f.write('\\n')\n",
    "\n",
    "print(f\"The dataset has been split successfully.\")\n",
    "print(f\"Train Set Size：{len(train_data)}\")\n",
    "print(f\"Val Set Size：{len(val_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f93dc6d-4590-4057-8ea6-8b27ed53ee60",
   "metadata": {},
   "source": [
    "## 加载模型和分词器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f08667c9-4d03-4c11-8bcf-63bd6a427a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fine/uv/transformers/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "249d8d2c-d1ae-4689-8620-121bdd482105",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/data/download-model/Qwen3-0.6B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96a1d0ec-99e0-42cd-8a9f-b40fede9e0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformers加载模型权重\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path,use_cache=False)\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae3db2c-ce4d-43ae-b499-8002fe5a4fbb",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## 调整数据的格式用于训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d993745f-7ea7-4561-b907-86ec4fe49510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "datset_path='../dataset/delicate_medical_r1/'\n",
    "train_dataset_path = os.path.join(datset_path,\"train.jsonl\")\n",
    "test_dataset_path = os.path.join(datset_path,\"val.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b80d6212-82db-4c75-9df5-df758d81c1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fc41d6f-9466-438c-9ce4-e47ddfccc3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=load_dataset('json',data_files={\n",
    "    'train':train_dataset_path,\n",
    "    'validation':test_dataset_path\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc2c105f-98e0-435c-8268-b39d1e59ad69",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"你是一个医学专家，你需要根据用户的问题，给出带有思考的回答。\"\n",
    "MAX_LENGTH = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a17c6cdc-e0be-4032-afd9-041b2696d9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_func(example):\n",
    "    \"\"\"\n",
    "    将数据集进行预处理\n",
    "    \"\"\" \n",
    "    instruction = f\"<|im_start|>system\\n{PROMPT}<|im_end|>\\n<|im_start|>user\\n{example['question']}<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "    response = f\"<think>{example['think']}</think>\\n{example['answer']}<|im_end|>\"\n",
    "\n",
    "    # 对完整对话进行编码\n",
    "    full_input = instruction + response\n",
    "    \n",
    "    # tokenize\n",
    "    tokenized = tokenizer(\n",
    "        full_input,\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH,\n",
    "        padding=False,\n",
    "        return_tensors=None\n",
    "    )\n",
    "    \n",
    "    # 对仅指令部分进行编码以计算标签位置\n",
    "    instruction_ids = tokenizer(\n",
    "        instruction,\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH,\n",
    "        padding=False,\n",
    "        return_tensors=None\n",
    "    )['input_ids']\n",
    "    \n",
    "    # 创建labels，instruction部分设为-100，response部分保持原值\n",
    "    labels = tokenized['input_ids'].copy()\n",
    "    instruction_len = len(instruction_ids)\n",
    "    for i in range(instruction_len):\n",
    "        if i < len(labels):\n",
    "            labels[i] = -100\n",
    "    \n",
    "    tokenized['labels'] = labels\n",
    "    \n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c5c7432-6d51-4fd7-9212-805ab9b80d93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2166/2166 [00:04<00:00, 475.81 examples/s]\n",
      "Map: 100%|██████████| 241/241 [00:00<00:00, 651.91 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset=dataset.map(process_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e12adb1d-e189-449f-818e-d532702b5e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=dataset['train']\n",
    "val_dataset=dataset['validation']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884d2037-fc96-4d5d-8646-35670498d4f1",
   "metadata": {},
   "source": [
    "## 准备lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cdb1f8a-45e8-46a9-94ee-4e4b0fbbbcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, TaskType,PeftModel,get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18dc29e1-cad7-408f-960d-06d19eb4fa9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 配置lora\n",
    "config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    inference_mode=False,  # 训练模式\n",
    "    r=8,  # Lora 秩\n",
    "    lora_alpha=32,  # Lora alaph，具体作用参见 Lora 原理\n",
    "    lora_dropout=0.1,  # Dropout 比例\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2732c8f4-b0ef-4c2e-99d8-53c6d329453c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,146,880 || all params: 597,196,800 || trainable%: 0.1920\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()  # 打印可训练参数，确认是否正确"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b92ac9f7-3f2e-4f4e-9592-98e35762ba5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确保可训练参数的 requires_grad 为 True\n",
    "for name, param in model.named_parameters():\n",
    "    if \"lora\" in name:  # 仅对 LoRA 参数设置 requires_grad=True\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False  # 冻结其他参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec2207d-de44-47d7-a473-fa5970fdca03",
   "metadata": {},
   "source": [
    "## 准备swanlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1717a98c-4170-429d-bd1a-2dd326c09716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import swanlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf642c60-c1fd-4f49-b6fd-a96607601186",
   "metadata": {},
   "outputs": [],
   "source": [
    "swanlab.config.update({\n",
    "    \"model\": \"Qwen3-0.6B\",\n",
    "    \"prompt\": PROMPT,\n",
    "    \"data_max_length\": MAX_LENGTH,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b229f8-2ebe-4e17-92af-ad260a5e2012",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 准备accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "241f9bfd-c7c2-45ba-8b40-0262131b91f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b93d0e08-39ce-4024-9cbf-74d3097e9172",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator=Accelerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e731835-f292-403e-82c3-08ab78354f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model,train_dataset,val_dataset=accelerator.prepare(model,train_dataset,val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2715059-4af3-4529-86b8-34219e5bc168",
   "metadata": {},
   "source": [
    "## 准备训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b493a897-2a72-41b0-a487-90e5c0fb9c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments,Trainer,DataCollatorForSeq2Seq,DataCollatorWithPadding\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4487c1b7-67b6-4aee-a984-ee82b7d6bd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50f73092-0a6e-4d0b-ac6b-57f0e8761a6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"../output/Qwen3-0.6B\",\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    logging_steps=10,\n",
    "    num_train_epochs=2,\n",
    "    save_steps=400,\n",
    "    learning_rate=1e-4,\n",
    "    save_on_each_node=True,\n",
    "    gradient_checkpointing=False,\n",
    "    report_to=\"swanlab\",\n",
    "    run_name=\"qwen3-0.6B\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031eba52-ff84-496a-a678-7f370208d9d8",
   "metadata": {},
   "source": [
    "## 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9010b83c-ef7e-46b3-9f59-33af744cfd9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: Tracking run with swanlab version 0.6.4                                   \n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: Run data will be saved locally in \u001b[35m\u001b[1m/home/adminad/zhangdw/workspace/finetuning/transformers/swanlog/run-20250629_042912-a3b1799d\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: 👋 Hi \u001b[1m\u001b[39mzhangdw156\u001b[0m\u001b[0m, welcome to swanlab!\n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: Syncing run \u001b[33mqwen3-0.6B\u001b[0m to the cloud\n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: 🏠 View project at \u001b[34m\u001b[4mhttps://swanlab.cn/@zhangdw156/transformers\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://swanlab.cn/@zhangdw156/transformers/runs/dga4anhfwnemdfwu7qjkq\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "<head>\n",
       "    <meta charset=\"UTF-8\">\n",
       "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
       "    <title>Show Iframe</title>\n",
       "    \n",
       "        <script>\n",
       "            function showIframe() {\n",
       "                var iframeHtml = '<iframe src=\"https://swanlab.cn/@zhangdw156/transformers/runs/dga4anhfwnemdfwu7qjkq\" width=100% height=\"600\" frameborder=\"no\"></iframe>';\n",
       "                document.getElementById('iframeContainer').innerHTML = iframeHtml;\n",
       "            }\n",
       "        </script>\n",
       "        \n",
       "</head>\n",
       "<body>\n",
       "    <style>\n",
       "        .interactive-button {\n",
       "            display: flex;\n",
       "            align-items: center;\n",
       "            height: 36px;\n",
       "            border: 0px;\n",
       "            background-color: #2c8f63;\n",
       "            color: white;\n",
       "            padding: 10px 20px;\n",
       "            transition: background-color 0.3s, transform 0.2s;\n",
       "        }\n",
       "\n",
       "        .interactive-button:hover {\n",
       "            background-color: #5cab87;\n",
       "            cursor: pointer;\n",
       "        }\n",
       "\n",
       "        .interactive-button:active { background-color: #217952; transform: scale(0.96); } </style> <br> <button \n",
       "        onclick=\"showIframe()\" class=\"interactive-button\"> <svg style=\"height: 16px; margin-right: 8px;\" viewBox=\"0 0 \n",
       "        46 46\" fill=\"none\"> <path d=\"M10.8439 21.1974C10.6414 21.2854 10.4477 21.3925 10.2655 21.5173L10.2069 \n",
       "        21.5652C10.1839 21.58 10.1625 21.5969 10.1429 21.6159C6.29135 24.6118 4.22831 29.4416 5.32646 34.282C5.94656 \n",
       "        37.0577 7.50461 39.5348 9.73801 41.2958C11.9714 43.0568 14.7436 43.994 17.5874 43.9495H18.0219C19.8864 \n",
       "        43.8697 21.7087 43.3694 23.3526 42.486C24.9964 41.6026 26.4193 40.3589 27.5147 38.848C28.61 37.3371 29.3496 \n",
       "        35.598 29.678 33.761C30.0065 31.9239 29.9153 30.0363 29.4112 28.2395C28.9181 26.4723 27.8919 24.8437 26.9937 \n",
       "        23.2551C25.4158 20.4653 23.8343 17.6764 22.2492 14.8884C21.7801 14.0647 21.3057 13.2465 20.8419 \n",
       "        12.4228C20.2315 11.3353 19.2746 10.1519 19.224 8.86183C19.1733 7.57176 20.2235 6.32701 21.5082 \n",
       "        6.07912C23.9284 5.61801 25.0639 8.24078 25.0693 8.23812C25.363 8.94035 25.9123 9.50489 26.6063 \n",
       "        9.81764C27.3002 10.1304 28.087 10.168 28.8077 9.92298C29.5283 9.67791 30.1291 9.1684 30.4885 8.49743C30.8479 \n",
       "        7.82646 30.9392 7.04405 30.7439 6.30835C30.1514 4.37314 28.9133 2.69953 27.2363 1.56656C25.7615 0.511704 \n",
       "        23.9847 -0.0372109 22.1719 0.00195984C20.9049 0.00893199 19.6532 0.27989 18.4967 0.797557C17.3402 1.31522 \n",
       "        16.3043 2.06823 15.4551 3.00856C14.49 4.08707 13.7984 5.38193 13.4389 6.78385C13.0794 8.18576 13.0624 9.6536 \n",
       "        13.3894 11.0635C13.52 11.593 13.6984 12.1095 13.9225 12.6067C14.5595 14.0514 15.4951 15.3681 16.284 \n",
       "        16.7355C17.2525 18.4147 18.2209 20.0948 19.1893 21.7758C20.1578 23.4568 21.1351 25.1449 22.1213 \n",
       "        26.8401C22.9209 28.2421 23.7925 29.4682 23.8805 31.1528C23.9175 32.0513 23.7682 32.9479 23.4419 \n",
       "        33.7859C23.1156 34.6239 22.6194 35.3854 21.9845 36.0223C21.3496 36.6592 20.5897 37.1578 19.7527 \n",
       "        37.4868C18.9157 37.8157 18.0196 37.9678 17.121 37.9336C14.0024 37.7923 11.6488 35.4814 11.1744 32.4588C10.58 \n",
       "        28.6419 13.552 26.5469 13.552 26.5469C14.1782 26.1785 14.6497 25.5955 14.8791 24.906C15.1084 24.2166 15.0801 \n",
       "        23.4673 14.7993 22.7971C14.5186 22.127 14.0044 21.5813 13.3521 21.2611C12.6998 20.941 11.9536 20.8682 11.2517 \n",
       "        21.0561C11.1174 21.0939 10.9856 21.1402 10.8572 21.1947\" fill=\"white\" /> <path d=\"M42.8101 31.5968C42.8109 \n",
       "        30.5198 42.7218 29.4445 42.5435 28.3823C42.2663 26.7069 41.7464 25.0808 41.0002 23.5552C40.5524 22.6463 \n",
       "        39.9874 21.7374 39.1024 21.2417C38.6593 20.9919 38.1589 20.8617 37.6502 20.8639C37.1416 20.8661 36.6423 \n",
       "        21.0006 36.2013 21.2541C35.7604 21.5077 35.393 21.8716 35.1352 22.3101C34.8775 22.7485 34.7382 23.2466 \n",
       "        34.7312 23.7552C34.7072 24.8773 35.3149 25.8875 35.768 26.9217C36.5212 28.6453 36.8623 30.5208 36.7642 \n",
       "        32.3993C36.6661 34.2777 36.1315 36.1075 35.2029 37.7433C35.146 37.8404 35.0952 37.941 35.051 38.0445C34.8623 \n",
       "        38.4842 34.7635 38.9573 34.7605 39.4358C34.7802 40.1222 35.0356 40.7808 35.4835 41.3011C35.9315 41.8214 \n",
       "        36.5449 42.1717 37.2207 42.2932C38.8759 42.589 40.1899 41.347 40.8856 39.9609C42.1643 37.3589 42.823 34.4961 \n",
       "        42.8101 31.5968Z\" fill=\"white\" /> <path d=\"M28.2309 11.8938C28.1761 11.9043 28.1218 11.9176 28.0683 \n",
       "        11.9338C27.9593 11.9642 27.8611 12.0249 27.7851 12.1088C27.7091 12.1928 27.6584 12.2965 27.6389 \n",
       "        12.408C27.6193 12.5195 27.6318 12.6343 27.6748 12.7391C27.7178 12.8438 27.7895 12.9343 27.8818 \n",
       "        12.9999C29.2375 14.0252 30.3809 15.3043 31.2482 16.7662C31.4838 17.1677 31.6888 17.5865 31.8612 \n",
       "        18.0189C32.0052 18.3921 32.1971 18.8799 32.6822 18.8532C33.0607 18.8346 33.2153 18.512 33.3192 \n",
       "        18.1895C33.8137 16.5125 33.9678 14.7534 33.7723 13.0159C33.6331 12.0693 33.4155 11.1359 33.122 \n",
       "        10.2252C33.0775 10.0047 32.9744 9.80029 32.8235 9.6335C32.7273 9.54627 32.6054 9.49262 32.4761 9.4806C32.3468 \n",
       "        9.46859 32.2171 9.49886 32.1065 9.56687C32.0016 9.65188 31.9115 9.75365 31.8399 9.86806C31.3956 10.4658 \n",
       "        30.825 10.9581 30.1687 11.3101C29.8377 11.4861 29.4893 11.6272 29.1292 11.7312C28.828 11.8192 28.5215 11.8325 \n",
       "        28.2309 11.8938Z\" fill=\"white\" /> </svg> Display SwanLab Board </button> <br> <div \n",
       "        id=\"iframeContainer\"></div> </body> </html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='136' max='136' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [136/136 02:54, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.597160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fine/uv/transformers/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=136, training_loss=0.20173054319970748, metrics={'train_runtime': 182.2887, 'train_samples_per_second': 23.765, 'train_steps_per_second': 0.746, 'total_flos': 1.2713575059554304e+16, 'train_loss': 0.20173054319970748, 'epoch': 2.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: \\ Updating experiment status..."
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bd5c80-31cb-4d27-832d-919f2ddb7611",
   "metadata": {},
   "source": [
    "## 验证结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96808120-8e54-4534-a535-104c11fd95fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2cd4f632-97a0-4e6c-9878-b9ca85154056",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ac290db-5915-42a7-911d-669995c2e9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": f\"{PROMPT}\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{dataset['validation']['question'][0]}\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a37564c-75bb-409c-b74c-696a79b54894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': '你是一个医学专家，你需要根据用户的问题，给出带有思考的回答。'},\n",
       " {'role': 'user',\n",
       "  'content': '1895年德国物理学教授伦琴的发现对医学影像学的发展有何具体影响？请从技术进步、学科建立和临床应用三个方面进行分析。'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd67474f-88ab-43bf-80cc-58b2cb020b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fbb12ee2-babc-4ae2-93ea-1f42dc1e0f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\n你是一个医学专家，你需要根据用户的问题，给出带有思考的回答。<|im_end|>\\n<|im_start|>user\\n1895年德国物理学教授伦琴的发现对医学影像学的发展有何具体影响？请从技术进步、学科建立和临床应用三个方面进行分析。<|im_end|>\\n<|im_start|>assistant\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "156c41a8-5e7d-4098-88cb-96846e899f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "/home/fine/uv/transformers/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to('cuda:0')\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    model_inputs.input_ids,\n",
    "    max_new_tokens=MAX_LENGTH,\n",
    ")\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9726ec7d-11ba-49d4-b0b7-43dc220e1cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>嗯，用户问的是1895年伦琴发现X射线对医学影像学的影响，特别是从技术、学科建立和临床应用三个方面的具体影响。首先，我需要回忆一下伦琴的贡献以及当时医学影像学的背景。\\n\\n首先，技术进步方面，伦琴的X射线发现了医学影像学的基础，这可能涉及他如何解释X射线的穿透和成像机制。记得他在1895年发表了一篇论文，提到X射线可以产生影像，这可能就是早期医学影像的雏形。所以技术进步方面，伦琴的工作直接推动了X射线成像技术的发展，比如X射线成像仪的发明，这可能让医生能够用X射线来诊断疾病，比如肺结核、骨折等，这应该属于技术进步的一部分。\\n\\n接下来是学科建立，伦琴的发现可能促使了医学影像学的学科化，比如形成了影像学作为独立的学科。之前的医学可能更关注解剖学和病理学，而影像学则需要专门的理论和实验方法。所以学科建立方面，可能需要提到影像学作为独立学科的成立，以及相关领域的研究，比如放射学的发展。\\n\\n临床应用方面，伦琴的工作对诊断疾病有帮助，比如肺结核、癌症、骨折等。他可能还发现了X射线成像仪的原理，这使得医生能够更准确地诊断疾病，从而改善医疗诊断的准确性和效率。另外，可能还涉及到放射治疗，但用户的问题主要集中在临床应用，所以需要确认是否直接提到放射治疗。\\n\\n不过，用户的问题可能希望更具体，比如伦琴如何具体应用X射线成像到临床，或者他可能与其他科学家合作，比如在1901年发表论文中提到的伦琴和阿诺德的研究，但用户的问题可能不需要涉及这些细节，只要从技术、学科和临床三个角度回答。\\n\\n可能需要检查伦琴的贡献是否确实属于医学影像学，比如他是否在1895年发表的论文中详细描述了X射线成像的原理，这可能就是技术进步中的关键点。另外，学科建立方面，影像学作为独立学科的成立，可能需要提到放射学作为学科的兴起，以及影像学与其他学科如医学、物理学、工程学的结合。\\n\\n临床应用方面，可能提到X射线成像仪的发明，让医生能够通过X射线观察病灶，从而更早诊断疾病，比如肺结核。此外，可能还涉及放射治疗的应用，但用户的问题可能更关注诊断，所以需要确认是否准确。\\n\\n总结下来，技术进步方面，伦琴的工作直接推动了X射线成像技术的发明，这使得医学影像学成为可能。学科建立方面，影像学作为独立学科的出现，以及放射学的发展。临床应用方面，X射线成像的应用，帮助诊断疾病，提高诊断准确性。\\n</think>\\n1895年德国物理学家伦琴发现X射线后，医学影像学得以建立。这一发现不仅推动了X射线成像技术的发展，还促使了影像学作为独立学科的建立。在临床应用方面，X射线成像技术使得医生能够通过X射线观察病灶，从而更早地诊断疾病，提高诊断的准确性和效率。伦琴的发现为医学影像学的发展奠定了基础，使得医学影像学成为现代医学的重要组成部分。'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d0ad404-1cfd-4e61-a32b-baeb33586111",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_text = f\"\"\"\n",
    "Question: {{dataset['validation']['question'][0]}}\n",
    "LLM:{response}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c50fd0be-4f34-499e-a1db-a536970f053a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nQuestion: {dataset['validation']['question'][0]}\\nLLM:<think>嗯，用户问的是1895年伦琴发现X射线对医学影像学的影响，特别是从技术、学科建立和临床应用三个方面的具体影响。首先，我需要回忆一下伦琴的贡献以及当时医学影像学的背景。\\n\\n首先，技术进步方面，伦琴的X射线发现了医学影像学的基础，这可能涉及他如何解释X射线的穿透和成像机制。记得他在1895年发表了一篇论文，提到X射线可以产生影像，这可能就是早期医学影像的雏形。所以技术进步方面，伦琴的工作直接推动了X射线成像技术的发展，比如X射线成像仪的发明，这可能让医生能够用X射线来诊断疾病，比如肺结核、骨折等，这应该属于技术进步的一部分。\\n\\n接下来是学科建立，伦琴的发现可能促使了医学影像学的学科化，比如形成了影像学作为独立的学科。之前的医学可能更关注解剖学和病理学，而影像学则需要专门的理论和实验方法。所以学科建立方面，可能需要提到影像学作为独立学科的成立，以及相关领域的研究，比如放射学的发展。\\n\\n临床应用方面，伦琴的工作对诊断疾病有帮助，比如肺结核、癌症、骨折等。他可能还发现了X射线成像仪的原理，这使得医生能够更准确地诊断疾病，从而改善医疗诊断的准确性和效率。另外，可能还涉及到放射治疗，但用户的问题主要集中在临床应用，所以需要确认是否直接提到放射治疗。\\n\\n不过，用户的问题可能希望更具体，比如伦琴如何具体应用X射线成像到临床，或者他可能与其他科学家合作，比如在1901年发表论文中提到的伦琴和阿诺德的研究，但用户的问题可能不需要涉及这些细节，只要从技术、学科和临床三个角度回答。\\n\\n可能需要检查伦琴的贡献是否确实属于医学影像学，比如他是否在1895年发表的论文中详细描述了X射线成像的原理，这可能就是技术进步中的关键点。另外，学科建立方面，影像学作为独立学科的成立，可能需要提到放射学作为学科的兴起，以及影像学与其他学科如医学、物理学、工程学的结合。\\n\\n临床应用方面，可能提到X射线成像仪的发明，让医生能够通过X射线观察病灶，从而更早诊断疾病，比如肺结核。此外，可能还涉及放射治疗的应用，但用户的问题可能更关注诊断，所以需要确认是否准确。\\n\\n总结下来，技术进步方面，伦琴的工作直接推动了X射线成像技术的发明，这使得医学影像学成为可能。学科建立方面，影像学作为独立学科的出现，以及放射学的发展。临床应用方面，X射线成像的应用，帮助诊断疾病，提高诊断准确性。\\n</think>\\n1895年德国物理学家伦琴发现X射线后，医学影像学得以建立。这一发现不仅推动了X射线成像技术的发展，还促使了影像学作为独立学科的建立。在临床应用方面，X射线成像技术使得医生能够通过X射线观察病灶，从而更早地诊断疾病，提高诊断的准确性和效率。伦琴的发现为医学影像学的发展奠定了基础，使得医学影像学成为现代医学的重要组成部分。\\n\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "87fe10ec-a450-460f-a35f-f7df2c4f7d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "test_text_list = []\n",
    "for i in random.sample(range(len(dataset['validation'])),3):\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": f\"{PROMPT}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{dataset['validation']['question'][0]}\"}\n",
    "    ]\n",
    "    text=tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to('cuda:0')\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        model_inputs.input_ids,\n",
    "        max_new_tokens=MAX_LENGTH,\n",
    "    )\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    \n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    response_text = f\"\"\"Question: {dataset['validation']['question'][i]}\\nLLM:{response}\"\"\"\n",
    "\n",
    "    test_text_list.append(swanlab.Text(response_text))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "535a8394-b504-4fd7-b2e4-8f3bf24be890",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Prediction': ['Question: 医生，我最近在深入研究神经递质的失活过程，特别是去甲肾上腺素（NA）的失活机制。能否详细解释一下NA失活的主要机制，包括摄取1（neuronal uptake）的具体过程，以及NA被摄取回神经末梢后的命运，特别是它如何被单胺氧化酶（MAO）破坏？\\nLLM:<think>嗯，用户问的是1895年伦琴对医学影像学的影响，特别是从技术进步、学科建立和临床应用三个方面。首先，我需要回忆一下伦琴的贡献。记得他发明了X射线，这应该是一个关键点。然后要分三个方面来分析。\\n\\n首先，技术进步方面。伦琴的X射线技术应该改变了医疗诊断的方式，比如X光成像。之前人们用的是玻璃管，现在X射线可以直接穿透物体，这样能更清晰地显示内部结构。可能还要提到成像的准确性，比如可以区分不同组织，帮助诊断骨折、肿瘤等。另外，X射线的高能量和穿透性可能让医生能够观察到更深层的结构，比如肺部或骨骼，这可能对诊断肺结核或骨髓炎有帮助。这部分需要详细点，说明具体技术如何应用，比如在放射科的应用。\\n\\n接下来是学科建立。伦琴的发明催生了放射医学，也就是放射物理学和放射医学的交叉学科。这可能包括放射治疗、医学影像学的进一步发展，比如核医学和放射化学。需要提到放射医学的起源，比如放射学作为一门独立的科学，可能在1895年之后逐渐形成。另外，可能还涉及放射治疗的发展，比如放射治疗的使用，以及如何将X射线用于治疗疾病，比如癌症。这部分要说明学科如何发展，可能包括放射治疗的应用，比如在放射治疗中的作用。\\n\\n第三点是临床应用。伦琴的X射线技术对诊断和治疗有重要影响。比如在诊断疾病时，X射线可以显示骨骼的结构变化，帮助诊断骨折、肿瘤等。同时，X射线的高密度和高灵敏度可能帮助医生快速发现病灶。另外，可能还有治疗应用，比如用于癌症的放射治疗，但需要确认时间线是否正确。比如，X射线治疗可能在20世纪初才开始临床应用，而伦琴在1895年已经发明了X射线，所以可能在治疗方面需要时间，但技术上已经成熟。另外，可能还有其他应用，比如X射线在手术中的使用，比如透视帮助医生定位器官，但这可能属于放射治疗的一部分。\\n\\n然后要检查是否覆盖了三个方面的所有点。技术进步方面，X射线的发明和应用，成像技术，比如X光成像。学科建立方面，放射医学的形成，放射治疗的发展。临床应用方面，诊断和治疗的应用。可能需要确认每个方面的具体例子是否准确，比如X光成像的具体应用，或者放射治疗的起源是否正确。\\n\\n另外，用户可能想知道伦琴的贡献如何推动了医学影像学的发展，所以需要强调技术如何让医学影像学更先进，学科如何整合放射学和医学，以及临床如何应用X射线。可能还需要提到其他相关人物，比如弗雷德里克·赫尔曼，但用户的问题只问到了伦琴，所以可能不需要提到其他贡献者，但学科建立部分可能需要提到其他人的贡献，但这里可能不需要。\\n\\n有没有可能遗漏了什么？比如，伦琴的X射线是否在1895年就已经存在，但可能用户的问题中的年份是1895，所以需要确认。是的，1895年伦琴确实发明了X射线，所以技术进步方面需要提到X射线的发明和应用，以及X光成像。学科建立方面，放射医学作为一门独立学科，可能在1895年之后才成立，但可能需要更准确的时间点，比如1895年之后不久，可能在1900年代逐渐发展。临床应用方面，可能需要说明X射线在诊断中的具体应用，比如肺部X光帮助诊断肺结核，或者X射线在骨骼检查中的使用，比如骨折诊断。\\n\\n总结下来，需要确保每个方面都有足够的细节，技术进步部分详细说明X射线的应用和成像技术，学科建立部分说明放射医学的形成，临床应用部分具体说明诊断和治疗的实例。可能还需要提到伦琴如何将X射线技术应用于医学，比如在放射治疗中的应用，或者X射线的高能量导致的特殊效应，如穿透性，这可能在临床诊断中帮助区分不同组织，比如肺部和骨骼的差异。\\n\\n另外，要确保语言流畅，结构清晰，分点明确，但用户要求的是思考过程，所以可能需要用更详细的思考步骤来组织答案，但用户可能只需要答案，不过根据问题，可能需要思考过程。不过用户的问题里已经给出答案，但需要检查是否正确，或者是否需要补充思考过程。不过根据问题，用户可能希望看到思考过程，但根据指示，可能只需要答案。不过用户可能希望我根据思考过程来构建答案，但根据问题，可能直接给出答案即可。不过可能需要确认答案的正确性，但根据已知信息，答案应该正确。\\n\\n可能还需要注意术语的正确使用，比如“X射线”、“X光成像”、“放射医学”等。另外，临床应用中的治疗可能包括放射治疗，但需要确认时间是否正确，伦琴在1895年发明X射线，而放射治疗可能是在之后，但技术上已经成熟，所以可能伦琴的X射线在治疗中的应用可能较早，但用户的问题可能不涉及治疗应用，所以可能需要忽略，或者说明治疗应用的时间。但根据问题，可能只需要技术、学科、临床应用三个方面的分析，所以答案中的临床应用部分可能需要提到诊断和治疗的应用，但具体例子可能需要更准确。\\n\\n总之，答案需要覆盖这三个方面，技术进步部分详细说明X射线的发明和应用，学科建立说明放射医学的形成，临床应用说明诊断和治疗的具体应用。需要确保每个部分都有足够的信息，但可能用户希望答案中的三个部分都有足够的细节，所以可能需要更详细的解释。\\n</think>\\n1895年，德国物理学家伦琴成功发明了X射线，这标志着医学影像学的诞生。X射线以其高能量和穿透性成为医学影像学的重要工具，能够清晰地显示人体内部结构，为医学诊断和治疗提供了新的方法。伦琴的发明不仅改变了医学影像学的发展，还促进了放射医学的学科建立，推动了放射治疗的发展，并在临床应用中为疾病诊断和治疗提供了重要支持。他的贡献对医学影像学的发展具有深远影响。', 'Question: 在使用原子生长法设计新分子时，如果新原子的位置适合形成环结构，应该如何处理？\\nLLM:<think>嗯，用户问的是1895年德国物理学家伦琴对医学影像学的具体影响，特别是技术进步、学科建立和临床应用三个方面。首先，我需要回忆一下伦琴的研究内容，尤其是他的X射线发现和应用。伦琴在1895年发表了《X射线的性质》一文，这应该是他首次正式描述X射线的发现。\\n\\n接下来，技术进步方面。伦琴的X射线应用是技术上的突破，比如他用X射线在人体内进行透视，这可能让医学影像学从二维图像转向三维图像，或者更精确的成像技术。比如，他可能用X射线在人体内形成对比度，从而看到内部结构。这里需要联系到当时的技术，比如当时可能没有超声波或其他技术，所以X射线成为第一个用于医学影像的手段。\\n\\n然后是学科建立，伦琴的发现应该促进了医学影像学的发展，可能推动了放射学作为独立学科的形成。比如，他可能提出了“X射线成像”作为学科名称，或者建立了相关的理论框架，比如放射学的基本原理。同时，他的研究也促进了放射学与医学的结合，比如临床诊断的应用。\\n\\n临床应用方面，伦琴的X射线应用可能帮助诊断疾病，比如癌症，因为X射线可以穿透组织，显示内部结构。比如，他可能用X射线在人体内进行扫描，帮助医生确定肿瘤的位置和大小，从而进行手术。这应该涉及到放射学在肿瘤治疗中的应用，比如放射治疗中的X射线治疗。\\n\\n不过，我需要确认伦琴的具体应用案例。比如，他在1895年用X射线在人体内进行透视，这可能是在1902年之后才开始商业化，但伦琴的贡献是理论基础。另外，他的研究可能还促进了放射学作为一门独立学科的发展，比如在1901年《医学影像学》杂志上发表，说明他推动了学科的建立。\\n\\n可能还需要考虑伦琴的贡献如何具体影响了医学影像学，比如从单纯的成像转向更深入的诊断，或者在临床中的应用扩展。比如，X射线成像在诊断中的应用，比如肺结核、骨折等，这可能就是临床应用的一部分。\\n\\n另外，技术进步可能包括X射线的发现和应用的普及，比如在1895年的发现后，伦琴的专利可能帮助技术的推广，或者他可能推动了X射线成像技术的标准化，比如建立成像设备或方法。\\n\\n学科建立方面，可能涉及到放射学作为独立学科的形成，比如他在1901年发表论文，说明他推动了学科的发展，而不仅仅是技术应用。同时，他的研究可能促进了放射学与医学的交叉，比如放射科的建立，或者放射学在医学中的应用。\\n\\n临床应用方面，可能包括X射线在诊断中的应用，比如在癌症、骨折、感染等疾病中的诊断，以及放射治疗中的应用，比如放射治疗中的X射线治疗。\\n\\n需要确保每个方面都有足够的细节支持，比如技术进步中的具体技术如X射线成像的原理，学科建立中的理论发展，临床应用中的具体疾病诊断和治疗案例。同时，要确保时间线正确，伦琴的贡献在1895年之后确实影响了医学影像学的发展，比如在1901年之后，但他的1895年的发现是基础。\\n\\n可能还需要注意用户的问题是否要强调伦琴的个人贡献，比如他如何通过自己的研究推动了医学影像学的发展，而不仅仅是技术上的应用。例如，他可能不仅发现X射线，还通过自己的研究建立了理论，从而促进了学科的发展。\\n\\n总结下来，技术进步方面，他的X射线成像技术应用；学科建立方面，放射学作为独立学科的形成；临床应用方面，X射线在诊断和治疗中的应用。需要将这些点清晰地组织起来，并用例子来说明每个方面的具体影响。\\n</think>\\n1895年，德国物理学家伦琴首次在人体内进行了X射线成像，这项技术标志着医学影像学的开端。他的研究不仅发现了X射线的性质，还推动了医学影像学的学科发展，促进了放射学作为一门独立学科的建立。此外，伦琴的X射线技术也广泛应用于临床诊断，帮助医生更好地了解病情，为医学影像学的发展奠定了基础。', 'Question: 医生，我最近在学习神经解剖学，想了解一下脉络丛的结构和它在大脑中的位置，能给我解释一下吗？\\nLLM:<think>嗯，用户问的是1895年伦琴发现对医学影像学的影响，特别是技术、学科建立和临床应用三个方面。我需要先回忆一下伦琴的贡献。伦琴是德国的物理学家，他的发现应该是X射线，对吧？那他的发现应该直接关系到医学影像学的发展。\\n\\n首先，技术进步方面。伦琴的发现应该让医学影像学有了基础，比如X射线成像技术的诞生。可能当时人们还不知道X射线是怎么工作的，但伦琴的实验结果让他意识到X射线的穿透能力，这可能直接导致了X射线成像技术的诞生。比如，他可能做了实验，比如用X射线照射物体，然后观察结果，从而建立了X射线成像的基础。所以技术进步应该包括X射线成像技术的产生，可能还有X射线成像的初步应用，比如在诊断疾病中的应用。\\n\\n然后是学科建立方面。伦琴的发现应该推动了医学影像学的学科发展。比如，他可能和当时的医学界合作，建立了一些相关的学科，或者推动了影像学作为独立的学科。可能还有影像学作为基础科学的一部分，比如放射医学、放射化学等。此外，伦琴的发现可能促进了放射物理学的发展，比如放射性研究，这可能对后来的放射学理论和应用有帮助。\\n\\n临床应用方面，伦琴的发现应该直接应用到临床诊断中。比如，他可能通过X射线成像帮助诊断骨折、肿瘤等疾病。比如，X射线成像在诊断骨折中的应用，或者X射线在肿瘤检查中的应用。比如，可能有医生使用X射线成像来检查骨骼系统，或者帮助诊断X线骨折的情况。此外，X射线成像可能被用于其他疾病诊断，比如肺部疾病或肌肉骨骼系统疾病。\\n\\n不过我需要确认伦琴的实验过程。比如，他可能做了什么实验？比如，他是否使用了X射线照射金属物体，然后观察X射线的衍射现象，从而产生图像？或者他是否在实验中观察到X射线在金属中的传播？比如，他可能在1895年做了实验，发现X射线穿透物体，形成图像，这可能就是X射线成像的基础。\\n\\n另外，学科建立方面，可能当时医学界对X射线的接受度不够，所以伦琴可能和当时的医生、物理学家、放射学家合作，建立影像学的学科，比如放射医学，或者放射化学。此外，可能还推动了放射物理学的发展，比如放射性物质的研究，这可能促进了医学影像学的进一步发展。\\n\\n临床应用方面，可能伦琴的发现被用来诊断骨折、肿瘤等疾病，比如X射线成像用于检查骨骼骨折，或者用于诊断肺部疾病，比如肺结核。此外，可能还有X射线成像用于其他疾病，比如X射线成像用于检查骨骼系统，或者用于诊断肿瘤，比如通过X射线成像观察肿瘤的大小和位置，从而帮助医生进行手术。\\n\\n可能还需要考虑伦琴的贡献是否被当时医学界广泛接受，比如是否被纳入医学影像学的课程中，或者是否成为医学影像学的里程碑事件。比如，1895年可能标志着X射线成像的正式诞生，或者成为医学影像学的重要组成部分。\\n\\n总结下来，技术进步方面是X射线成像技术的诞生，学科建立方面是放射医学和放射物理学的发展，临床应用方面是X射线成像在诊断中的应用，比如骨折、肿瘤等疾病。需要确保每个点都覆盖到，并且逻辑连贯，没有遗漏关键点。\\n</think>\\n1895年，德国物理学家伦琴在实验中发现X射线穿透物体并产生图像，这直接推动了医学影像学的发展。技术进步方面，伦琴的发现使得X射线成像技术得以诞生，为医学影像学奠定了基础。学科方面，伦琴的发现促进了放射医学和放射物理学的发展，使得医学影像学成为独立的科学领域。临床应用方面，X射线成像在诊断骨折、肿瘤等疾病中具有重要应用，为现代医学提供了重要的影像诊断工具。']}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swanlab.log({\"Prediction\": test_text_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eac8168f-1182-4f93-90e6-951b59e9c504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: 🏠 View project at \u001b[34m\u001b[4mhttps://swanlab.cn/@zhangdw156/transformers\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://swanlab.cn/@zhangdw156/transformers/runs/skg1htqqz2dbi1gymkypo\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: Waiting for uploading complete\n",
      "                                                                                                    "
     ]
    }
   ],
   "source": [
    "swanlab.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e746b2-5224-416a-b4fd-abb6d327cfb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
