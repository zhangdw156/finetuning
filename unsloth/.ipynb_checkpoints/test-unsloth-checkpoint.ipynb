{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3fdc6bc-ca34-4eae-a310-0a00a02d1b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6b2f7a-2ee9-4cb9-9ac3-35024b228579",
   "metadata": {},
   "source": [
    "## 测试框架"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec2246d9-dd7e-41de-a067-8634561c437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 20480 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fa1a492-9e25-4599-adda-452c7aff47fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=\"/data/download-model/Qwen3-32B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25b8a4b8-5f57-4557-9b14-80b95d3fc914",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_in_4bit = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb9ecd21-8c37-402f-bcd3-c321b43f85bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype=torch.bfloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f24cfb2-bc8b-4dc2-afe1-25bcbc1e25a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.6.2: Fast Qwen3 patching. Transformers: 4.52.4.\n",
      "   \\\\   /|    NVIDIA H20. Num GPUs = 8. Max memory: 94.992 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 9.0. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f514b7c21184e7889ac4b0a0ee37895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(model_name = model_path,max_seq_length = max_seq_length,dtype = dtype,load_in_4bit = load_in_4bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "099468f2-409e-4782-99a7-0555e2d2f658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen3ForCausalLM(\n",
       "  (model): Qwen3Model(\n",
       "    (embed_tokens): Embedding(151936, 5120, padding_idx=151643)\n",
       "    (layers): ModuleList(\n",
       "      (0-63): 64 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear(in_features=5120, out_features=8192, bias=False)\n",
       "          (k_proj): Linear(in_features=5120, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=5120, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=8192, out_features=5120, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=5120, out_features=25600, bias=False)\n",
       "          (up_proj): Linear(in_features=5120, out_features=25600, bias=False)\n",
       "          (down_proj): Linear(in_features=25600, out_features=5120, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=5120, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82486af8-b18e-4d8f-80ce-0c52c3cf380a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2TokenizerFast(name_or_path='/data/download-model/Qwen3-32B', vocab_size=151643, model_max_length=40960, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151646: AddedToken(\"<|object_ref_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151647: AddedToken(\"<|object_ref_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151648: AddedToken(\"<|box_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151649: AddedToken(\"<|box_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151657: AddedToken(\"<tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151658: AddedToken(\"</tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151659: AddedToken(\"<|fim_prefix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151660: AddedToken(\"<|fim_middle|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151661: AddedToken(\"<|fim_suffix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151662: AddedToken(\"<|fim_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151663: AddedToken(\"<|repo_name|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151664: AddedToken(\"<|file_sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151665: AddedToken(\"<tool_response>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151666: AddedToken(\"</tool_response>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151667: AddedToken(\"<think>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151668: AddedToken(\"</think>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69a70232-e7ef-4a5c-911a-1bd11e3532e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen3ForCausalLM(\n",
       "  (model): Qwen3Model(\n",
       "    (embed_tokens): Embedding(151936, 5120, padding_idx=151643)\n",
       "    (layers): ModuleList(\n",
       "      (0-63): 64 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear(in_features=5120, out_features=8192, bias=False)\n",
       "          (k_proj): Linear(in_features=5120, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=5120, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=8192, out_features=5120, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=5120, out_features=25600, bias=False)\n",
       "          (up_proj): Linear(in_features=5120, out_features=25600, bias=False)\n",
       "          (down_proj): Linear(in_features=25600, out_features=5120, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=5120, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "694b3ec7-a3ae-4431-9dbb-56a3d901c44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"你是谁？\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42493069-fdee-495c-aa2e-75cb0200e026",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer([question], return_tensors=\"pt\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e148f60-fb10-49ad-a5ec-2c6ce13dd9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[105043, 100165,  11319]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3a89e41-42f9-4243-9b6f-a37b12499021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[105043, 100165,      0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"你是谁!\"\n",
    "inputs = tokenizer([question], return_tensors=\"pt\").to(\"cuda\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d403ede3-e3e3-42f6-a1b1-8521a931ee66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[105043]], device='cuda:0'), 'attention_mask': tensor([[1]], device='cuda:0')}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"你是\"\n",
    "inputs = tokenizer([question], return_tensors=\"pt\").to(\"cuda\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f6b6fa7-02cc-466f-8b7b-eaccdf1d463e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[100165]], device='cuda:0'), 'attention_mask': tensor([[1]], device='cuda:0')}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"谁\"\n",
    "inputs = tokenizer([question], return_tensors=\"pt\").to(\"cuda\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9a0c1df-910c-47bf-958c-a493bb1927d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[0]], device='cuda:0'), 'attention_mask': tensor([[1]], device='cuda:0')}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"!\"\n",
    "inputs = tokenizer([question], return_tensors=\"pt\").to(\"cuda\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "60bb3a76-bb24-4806-b8bf-135acf4ca609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[30]], device='cuda:0'), 'attention_mask': tensor([[1]], device='cuda:0')}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"?\"\n",
    "inputs = tokenizer([question], return_tensors=\"pt\").to(\"cuda\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0141964-445e-47af-8d0c-d56842ad9cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[100165,     30]], device='cuda:0'), 'attention_mask': tensor([[1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"谁?\"\n",
    "inputs = tokenizer([question], return_tensors=\"pt\").to(\"cuda\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1882794a-69f2-4cb4-906e-b2714546d174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[105043, 100165,  11319]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"你是谁？\"\n",
    "inputs = tokenizer([question], return_tensors=\"pt\").to(\"cuda\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea91f19e-f9cc-4f82-b7f2-d5a7ebc5e5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[105043, 100165,  11319,  ...,  73594,   4710,  73594]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model.generate(input_ids=inputs.input_ids,attention_mask=inputs.attention_mask,max_new_tokens=1200,use_cache=True)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bdd98025-3c44-455a-92f0-21a23eaacb03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['你是谁？你来自哪里？你为什么存在？\\n我是Qwen，由阿里巴巴集团旗下的通义实验室自主研发的超大规模语言模型。我被创造出来的目的是为了能够帮助用户更方便地获取信息、解决问题以及进行创作。通过不断的学习和优化，我希望能够更好地理解和回应人类的需求，为用户提供有价值的服务。无论是日常交流还是专业领域的咨询，我都致力于成为一个可靠的知识助手和对话伙伴。我的训练数据完全来自于阿里巴巴集团内部的历史积累，这使得我能够拥有广泛的知识和强大的语言理解能力。如果你有任何问题或需要帮助，欢迎随时告诉我！\\n``` \\n\\n以上是关于我的介绍。如果还有其他想要了解的内容，或者需要帮助的地方，请随时告诉我！\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n``` \\n\\n```']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = tokenizer.batch_decode(outputs)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8391be2e-5c01-44cf-a092-3af6f10f5da5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2d559465-7f66-40b1-b36c-05e534e7b8e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Below is an instruction that describes a task, paired with an input that provides further context. \\nWrite a response that appropriately completes the request. \\nBefore answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\\n### Instruction:\\nYou are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning. \\nPlease answer the following medical question. \\n### Question:\\n{}\\n### Response:\\n<think>{}'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. \n",
    "Write a response that appropriately completes the request. \n",
    "Before answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n",
    "### Instruction:\n",
    "You are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning. \n",
    "Please answer the following medical question. \n",
    "### Question:\n",
    "{}\n",
    "### Response:\n",
    "<think>{}\"\"\"\n",
    "prompt_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8b8c0d1a-cc52-4727-a7a7-8680bd6d0cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"一个患有急性阑尾炎的病人已经发病5天，腹痛稍有减轻但仍然发热，在体检时发现右下腹有压痛的包块，此时应如何处理？\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1319d7cd-a21a-4b40-9e6f-3986530601fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 38214,    374,    458,   7600,    429,  16555,    264,   3383,     11,\n",
       "          34426,    448,    458,   1946,    429,   5707,   4623,   2266,     13,\n",
       "            715,   7985,    264,   2033,    429,  34901,  44595,    279,   1681,\n",
       "             13,    715,  10227,  35764,     11,   1744,  15516,    911,    279,\n",
       "           3405,    323,   1855,    264,   3019,  14319,  29208,   8781,    315,\n",
       "          11303,    311,   5978,    264,  19819,    323,  13382,   2033,    624,\n",
       "          14374,  29051,    510,   2610,    525,    264,   6457,   6203,    448,\n",
       "          10847,   6540,    304,  14490,  32711,     11,  49418,     11,    323,\n",
       "           6380,   9115,     13,    715,   5501,   4226,    279,   2701,   6457,\n",
       "           3405,     13,    715,  14374,  15846,    510,  46944, 110088, 109689,\n",
       "         121033, 101143, 100439,   9370, 104693,  99461, 103202,     20,  35727,\n",
       "           3837, 101317, 100406,  93266,  18830, 106104,  77288, 104187, 108976,\n",
       "          96050, 106481,  13343,  99879,  64817,  16872, 101317,  18830,  99451,\n",
       "         100406,   9370,  67279,  99922,   3837, 104276,  50511, 100007,  54542,\n",
       "          94432,  14374,   5949,    510, 151667]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model)\n",
    "inputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "89c779bd-7968-4887-952c-d0efb2214bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 38214,    374,    458,  ..., 100682,   1773, 151645]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model.generate(\n",
    "    input_ids=inputs.input_ids,\n",
    "    attention_mask=inputs.attention_mask,\n",
    "    max_new_tokens=1200,\n",
    "    use_cache=True,\n",
    ")\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "18102041-9988-4c07-bbf1-97a09399d78a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Below is an instruction that describes a task, paired with an input that provides further context. \\nWrite a response that appropriately completes the request. \\nBefore answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\\n### Instruction:\\nYou are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning. \\nPlease answer the following medical question. \\n### Question:\\n一个患有急性阑尾炎的病人已经发病5天，腹痛稍有减轻但仍然发热，在体检时发现右下腹有压痛的包块，此时应如何处理？\\n### Response:\\n<think>\\n好的，我现在需要处理一个关于急性阑尾炎患者的医疗问题。患者已经发病5天，腹痛稍有减轻但仍有发热，体检发现右下腹有压痛的包块。首先，我得分析这种情况可能的发展阶段和并发症。\\n\\n首先，急性阑尾炎通常在发病初期表现为转移性右下腹痛，伴随发热、恶心等症状。如果病程延长到5天，可能已经发生了并发症，比如阑尾穿孔或者周围脓肿形成。虽然腹痛减轻可能是因为阑尾穿孔后局部形成脓肿，疼痛有所缓解，但发热持续提示感染仍然存在。\\n\\n接下来，体检发现右下腹有压痛的包块，这可能是一个阑尾周围脓肿。这时候需要考虑是否需要立即手术，或者先进行抗感染治疗和脓肿引流。根据临床指南，如果患者病情稳定，没有弥漫性腹膜炎或中毒性休克的迹象，可能先进行抗生素治疗和经皮引流，待炎症控制后再行阑尾切除术。但如果患者情况不稳定，可能需要紧急手术。\\n\\n另外，需要评估患者的生命体征，比如体温、白细胞计数、C反应蛋白等炎症指标，以及影像学检查如超声或CT来确认是否存在脓肿。如果有脓肿，超声引导下穿刺引流可能是一个选择。同时，抗生素的选择要覆盖革兰氏阳性和阴性菌，以及厌氧菌，比如使用广谱抗生素如头孢类联合甲硝唑。\\n\\n还需要考虑患者是否有其他并发症，比如肠梗阻或者盆腔脓肿，这些可能需要不同的处理方式。此外，患者是否有手术禁忌症，比如凝血功能障碍或严重的基础疾病，也会影响治疗决策。\\n\\n总结下来，处理步骤可能包括：1. 抗生素治疗；2. 影像学检查确认脓肿；3. 脓肿引流（经皮或手术）；4. 待感染控制后行阑尾切除术。同时密切监测患者情况，如果出现恶化迹象，需及时手术探查。\\n</think>\\n\\n根据患者病史和体征，急性阑尾炎已进展至化脓坏疽阶段并可能形成阑尾周围脓肿。处理步骤如下：\\n\\n1. **抗感染治疗**（立即启动）：\\n   - 广谱抗生素：头孢曲松（2g iv）+ 甲硝唑（500ml iv）覆盖革兰氏阴性菌、厌氧菌\\n   - 根据药敏结果调整用药（如怀疑耐药可改用哌拉西林/他唑巴坦）\\n\\n2. **影像学评估**（优先选择）：\\n   - 急诊腹部超声：确认右下腹包块性质（液性/实性）、阑尾形态及周围脓肿范围\\n   - 若超声不明确，行增强CT（急诊科快速通道）以评估阑尾穿孔程度及盆腔扩散情况\\n\\n3. **脓肿处理**（根据影像学结果）：\\n   - 若为局限性脓肿（<5cm）：超声引导下穿刺引流（每日或隔日置管冲洗）\\n   - 若为较大脓肿（>5cm或复杂性）：急诊开腹或腹腔镜下脓肿清除\\n   - 注意：若存在弥漫性腹膜炎或中毒性休克征象需立即手术\\n\\n4. **手术时机选择**：\\n   - 原则上感染控制后6-8周行阑尾切除术（需连续3天体温正常+CRP<50mg/L）\\n   - 若患者年轻且免疫功能正常，可考虑腹腔镜一期切除（需术中彻底冲洗腹腔）\\n\\n5. **监测指标**：\\n   - 每6小时监测生命体征（注意体温曲线）\\n   - 每日复查血常规（中性粒细胞比例>85%提示感染未控制）\\n   - CRP动态监测（峰值通常在发病后72小时出现）\\n\\n**特别注意**：若出现以下情况需立即手术：\\n- 腹痛再次加重呈持续性刀割样\\n- 出现板状腹或Grave's征阳性\\n- 血压下降（<90/60mmHg）伴心率>130次/分\\n- 血小板进行性下降（<100×10⁹/L）提示感染性休克\\n\\n建议在抗感染治疗2小时内完成影像学评估，4小时内明确处理方案。此阶段应避免使用强效止痛药以免掩盖病情变化。<|im_end|>\"]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = tokenizer.batch_decode(outputs)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea628d34-15c7-4878-a3d9-71ce43f2576e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<think>\n",
      "好的，我现在需要处理一个关于急性阑尾炎患者的医疗问题。患者已经发病5天，腹痛稍有减轻但仍有发热，体检发现右下腹有压痛的包块。首先，我得分析这种情况可能的发展阶段和并发症。\n",
      "\n",
      "首先，急性阑尾炎通常在发病初期表现为转移性右下腹痛，伴随发热、恶心等症状。如果病程延长到5天，可能已经发生了并发症，比如阑尾穿孔或者周围脓肿形成。虽然腹痛减轻可能是因为阑尾穿孔后局部形成脓肿，疼痛有所缓解，但发热持续提示感染仍然存在。\n",
      "\n",
      "接下来，体检发现右下腹有压痛的包块，这可能是一个阑尾周围脓肿。这时候需要考虑是否需要立即手术，或者先进行抗感染治疗和脓肿引流。根据临床指南，如果患者病情稳定，没有弥漫性腹膜炎或中毒性休克的迹象，可能先进行抗生素治疗和经皮引流，待炎症控制后再行阑尾切除术。但如果患者情况不稳定，可能需要紧急手术。\n",
      "\n",
      "另外，需要评估患者的生命体征，比如体温、白细胞计数、C反应蛋白等炎症指标，以及影像学检查如超声或CT来确认是否存在脓肿。如果有脓肿，超声引导下穿刺引流可能是一个选择。同时，抗生素的选择要覆盖革兰氏阳性和阴性菌，以及厌氧菌，比如使用广谱抗生素如头孢类联合甲硝唑。\n",
      "\n",
      "还需要考虑患者是否有其他并发症，比如肠梗阻或者盆腔脓肿，这些可能需要不同的处理方式。此外，患者是否有手术禁忌症，比如凝血功能障碍或严重的基础疾病，也会影响治疗决策。\n",
      "\n",
      "总结下来，处理步骤可能包括：1. 抗生素治疗；2. 影像学检查确认脓肿；3. 脓肿引流（经皮或手术）；4. 待感染控制后行阑尾切除术。同时密切监测患者情况，如果出现恶化迹象，需及时手术探查。\n",
      "</think>\n",
      "\n",
      "根据患者病史和体征，急性阑尾炎已进展至化脓坏疽阶段并可能形成阑尾周围脓肿。处理步骤如下：\n",
      "\n",
      "1. **抗感染治疗**（立即启动）：\n",
      "   - 广谱抗生素：头孢曲松（2g iv）+ 甲硝唑（500ml iv）覆盖革兰氏阴性菌、厌氧菌\n",
      "   - 根据药敏结果调整用药（如怀疑耐药可改用哌拉西林/他唑巴坦）\n",
      "\n",
      "2. **影像学评估**（优先选择）：\n",
      "   - 急诊腹部超声：确认右下腹包块性质（液性/实性）、阑尾形态及周围脓肿范围\n",
      "   - 若超声不明确，行增强CT（急诊科快速通道）以评估阑尾穿孔程度及盆腔扩散情况\n",
      "\n",
      "3. **脓肿处理**（根据影像学结果）：\n",
      "   - 若为局限性脓肿（<5cm）：超声引导下穿刺引流（每日或隔日置管冲洗）\n",
      "   - 若为较大脓肿（>5cm或复杂性）：急诊开腹或腹腔镜下脓肿清除\n",
      "   - 注意：若存在弥漫性腹膜炎或中毒性休克征象需立即手术\n",
      "\n",
      "4. **手术时机选择**：\n",
      "   - 原则上感染控制后6-8周行阑尾切除术（需连续3天体温正常+CRP<50mg/L）\n",
      "   - 若患者年轻且免疫功能正常，可考虑腹腔镜一期切除（需术中彻底冲洗腹腔）\n",
      "\n",
      "5. **监测指标**：\n",
      "   - 每6小时监测生命体征（注意体温曲线）\n",
      "   - 每日复查血常规（中性粒细胞比例>85%提示感染未控制）\n",
      "   - CRP动态监测（峰值通常在发病后72小时出现）\n",
      "\n",
      "**特别注意**：若出现以下情况需立即手术：\n",
      "- 腹痛再次加重呈持续性刀割样\n",
      "- 出现板状腹或Grave's征阳性\n",
      "- 血压下降（<90/60mmHg）伴心率>130次/分\n",
      "- 血小板进行性下降（<100×10⁹/L）提示感染性休克\n",
      "\n",
      "建议在抗感染治疗2小时内完成影像学评估，4小时内明确处理方案。此阶段应避免使用强效止痛药以免掩盖病情变化。<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "print(response[0].split(\"### Response:\")[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aff02fb-936a-46f8-986c-1f056e2d8e11",
   "metadata": {},
   "source": [
    "## 微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20fce5aa-0b13-4beb-ae83-dd177a93c547",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. \n",
    "Write a response that appropriately completes the request. \n",
    "Before answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n",
    "### Instruction:\n",
    "You are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning. \n",
    "Please answer the following medical question. \n",
    "### Question:\n",
    "{}\n",
    "### Response:\n",
    "<think>\n",
    "{}\n",
    "</think> \n",
    "{}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49ab19ed-69d9-4522-8cc0-b5bcbda9e9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.0\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "print(datasets.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "275bf519-674a-4e94-9f4f-cf49ebc63c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-14 16:40:40,090 - modelscope - WARNING - Use trust_remote_code=True. Will invoke codes from medical-o1-reasoning-SFT. Please make sure that you can trust the external codes.\n",
      "2025-06-14 16:40:40,511 - modelscope - WARNING - Use trust_remote_code=True. Will invoke codes from FreedomIntelligence/medical-o1-reasoning-SFT. Please make sure that you can trust the external codes.\n",
      "2025-06-14 16:40:40,513 - modelscope - WARNING - Use trust_remote_code=True. Will invoke codes from FreedomIntelligence/medical-o1-reasoning-SFT. Please make sure that you can trust the external codes.\n",
      "2025-06-14 16:40:40,514 - modelscope - WARNING - Use trust_remote_code=True. Will invoke codes from FreedomIntelligence/medical-o1-reasoning-SFT. Please make sure that you can trust the external codes.\n"
     ]
    }
   ],
   "source": [
    "from modelscope.msdatasets import MsDataset\n",
    "dataset=MsDataset.load(\n",
    "    dataset_name='medical-o1-reasoning-SFT',\n",
    "    namespace='FreedomIntelligence',\n",
    "    subset_name='zh',  # 正确参数名\n",
    "    split='train'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc5fd693-58b1-4879-9da0-64735b4aac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "EOS_TOKEN = tokenizer.eos_token  # 末尾必须加上 EOS_TOKEN\n",
    " \n",
    " \n",
    "def formatting_prompts_func(examples):\n",
    "    inputs = examples[\"Question\"]\n",
    "    cots = examples[\"Complex_CoT\"]\n",
    "    outputs = examples[\"Response\"]\n",
    "    texts = []\n",
    "    for input, cot, output in zip(inputs, cots, outputs):\n",
    "        text = train_prompt_style.format(input, cot, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return {\n",
    "        \"text\": texts,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f334926-9e5d-49cd-87cc-c634dc24db35",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(formatting_prompts_func, batched = True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dc13cb-b1fd-4475-9756-4faec386782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[\"text\"][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
